# -*- coding: utf-8 -*-
"""Optimized_Scheduling_Brute_Force.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SQpUbRaoseI1KtAcuTH-41TF7pHSBcAH
"""

# Imports
import random
import networkx as nx
from networkx import Graph
from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
import copy as copy
import multiprocessing
import itertools

# Function Definitions

def comm_cost(route, message_size):
    """
    Calculates the communication cost based on the route and message size.

    Args:
        route (list): List of nodes representing the route.
        message_size (int): Size of the message.

    Returns:
        tuple: The communication cost and the adjusted message size.
    """
    hops = len(route) - 1
    bandwidth = 32  # Insert the bandwidth of your links here
    m_size = int(message_size / bandwidth)
    cost = hops * m_size
    return cost, m_size


def Extract_Highest_Priority(jobs, Ready_Jobs):
    """
    Extracts the job with the highest priority from the list of ready jobs.

    Args:
        jobs (dict): Dictionary containing job information.
        Ready_Jobs (list): List of job indices that are ready to be scheduled.

    Returns:
        int: Index of the job with the highest priority.
    """
    priorities = []
    for i in range(len(Ready_Jobs)):
        prior = jobs[Ready_Jobs[i]]['priority']
        priorities.append(prior)
    min_value = min(priorities)
    idx = priorities.index(min_value)
  
    return Ready_Jobs[idx]


def traffic_control_reserve(Injection, path, message_size, path_cost, overwrite):
    """
    Calculates the delta cost for traffic control reservation.

    Args:
        Injection (int): Injection time.
        path (list): List of nodes representing the path.
        message_size (int): Size of the message.
        path_cost (int): Cost of the path.
        overwrite (int): Flag to indicate if collision should be overwritten.

    Returns:
        int: Delta cost.
    """
    Current_Router_start = Injection - message_size
    Current_Router_end = Injection + path_cost

    for count in range(len(path)-1):
        Current_Router = [path[count], path[count+1]]
        Current_Router_start = Current_Router_start + message_size
        Current_Router_end = Current_Router_start + message_size
        Current_Router_start, Current_Router_end = check_collision(Current_Router, Current_Router_start, Current_Router_end, overwrite)
    
    Delta_cost = Current_Router_end - (Injection + path_cost)

    return Delta_cost


def check_collision(Current_Router, Current_Router_start, Current_Router_end, overwrite):
    """
    Checks for collisions and resolves them if necessary.

    Args:
        Current_Router (list): List of nodes representing the current router.
        Current_Router_start (int): Start time of the current router.
        Current_Router_end (int): End time of the current router.
        overwrite (int): Flag to indicate if collision should be overwritten.

    Returns:
        tuple: The adjusted start and end time of the current router.
    """
    list_name = str(np.min(Current_Router)) + str(np.max(Current_Router))
    list_name = "cl_" + list_name
  
    current_list = globals()[list_name]

    for search in range(len(current_list)):
        while (Current_Router_start >= current_list[search][0] and Current_Router_start < current_list[search][1]) or (Current_Router_end > current_list[search][0] and Current_Router_end <= current_list[search][1]):
            Current_Router_start = Current_Router_start + 1
            Current_Router_end = Current_Router_end + 1
  
    if overwrite == 1:
        globals()[list_name].append([Current_Router_start, Current_Router_end])

    return Current_Router_start, Current_Router_end


def find_path(connections, start_node, end_node):
    """
    Finds a path between two nodes using Breadth-First Search.

    Args:
        connections (list): List of tuples representing the connections between nodes.
        start_node (int): Starting node.
        end_node (int): Ending node.

    Returns:
        list or None: List of nodes representing the path if a path is found, None otherwise.
    """
    nodes = set()
    for connection in connections:
        nodes.add(connection[0])
        nodes.add(connection[1])

    adjacency_list = {}
    for connection in connections:
        node1 = connection[0]
        node2 = connection[1]
        if node1 not in adjacency_list:
            adjacency_list[node1] = []
        if node2 not in adjacency_list:
            adjacency_list[node2] = []
        adjacency_list[node1].append(node2)
        adjacency_list[node2].append(node1)

    visited = set()
    queue = [[start_node]]
    while queue:
        path = queue.pop(0)
        node = path[-1]
        if node == end_node:
            return path
        elif node not in visited:
            for neighbor in adjacency_list.get(node, []):
                new_path = list(path)
                new_path.append(neighbor)
                queue.append(new_path)
            visited.add(node)
    return None


def dict_to_dataframe(dictionary):
    """
    Converts a dictionary into a Pandas DataFrame.

    Args:
        dictionary (dict): Dictionary to be converted.

    Returns:
        pandas.DataFrame: DataFrame containing the dictionary entries.
    """
    df = pd.DataFrame()

    for key, attributes in dictionary.items():
        attr_df = pd.DataFrame.from_dict(attributes, orient='index').transpose()
        df = pd.concat([df, attr_df], ignore_index=True)
    
    return df


def Schedule(jobs, routes, end_systems, messages, links):
    """
    Schedules the jobs and calculates the makespan.

    Args:
        jobs (dict): Dictionary containing job information.
        routes (dict): Dictionary containing routes between end systems.
        end_systems (list): List of end systems (processors).
        messages (dict): Dictionary containing message information.
        links (list): List of connections between processors and routers.

    Returns:
        int: Makespan of the schedule.
    """
    Ready_Jobs = []
    Finished_jobs = []

    processor_endTime = [0 for j in range(len(end_systems))]

    for i in range(len(jobs)):
        if jobs[i]['parents'] == []:
            Ready_Jobs.append(i)

    while Ready_Jobs != []:
        Job = Extract_Highest_Priority(jobs, Ready_Jobs)
        End_system = jobs[Job]['end_system']
        execution_time = jobs[Job]['wcet']

        parents_job = jobs[Job]['parents']
        parents_end_times = [jobs[parent]['end_time'] for parent in parents_job]
        parents_end_times.append(processor_endTime[End_system - 1])
        maxi = max(parents_end_times)
        jobs[Job]["start_time"] = maxi
        processor_endTime[End_system - 1] = maxi + execution_time
        jobs[Job]["end_time"] = processor_endTime[End_system - 1]

        Finished_jobs.append(Job)
        Ready_Jobs.remove(Job)

        children = jobs[Job]['children']

        for child in children:
            if set(jobs[child]['parents']).issubset(Finished_jobs):
                Ready_Jobs.append(child)
                Ready_Jobs = list(set(Ready_Jobs))

    for i in range(len(links)):
        name = "cl_" + str(links[i][0]) + str(links[i][1])
        globals()[name] = []

    Msg_counter = 0
    for i in Finished_jobs:
        processor_sender = jobs[i]['end_system']
        Msg_Size = jobs[i]['message_size']
        children = jobs[i]['children']
        Injection_time = jobs[i]['end_time']
        for j in children:
            processor_receiver = jobs[j]['end_system']
            if processor_sender == processor_receiver:
                Msg_Size = 0
                Route = []
                messages[Msg_counter]['route'] = []
                messages[Msg_counter]['parent'] = i
                messages[Msg_counter]['child'] = j
                messages[Msg_counter]['start_time'] = Injection_time
                messages[Msg_counter]['finish_time'] = Injection_time
                messages[Msg_counter]['sender'] = processor_sender
                messages[Msg_counter]['receiver'] = processor_receiver
                Msg_counter += 1
            else:
                Route = routes.get((processor_sender, processor_receiver))
                Cost, msize = comm_cost(Route, Msg_Size)
                col_costs = traffic_control_reserve(Injection_time, Route, msize, Cost, 1)
                comm_costs = Cost + col_costs
                messages[Msg_counter]['start_time'] = Injection_time
                messages[Msg_counter]['finish_time'] = Injection_time + comm_costs
                messages[Msg_counter]['parent'] = i
                messages[Msg_counter]['child'] = j
                messages[Msg_counter]['route'] = Route
                messages[Msg_counter]['sender'] = processor_sender
                messages[Msg_counter]['receiver'] = processor_receiver
                if jobs[j]['start_time'] < messages[Msg_counter]['finish_time']:
                    starting_time = jobs[j]['start_time']
                    ending_time = jobs[j]['end_time']
                    diff = messages[Msg_counter]['finish_time'] - starting_time
                    jobs[j]['start_time'] = starting_time + diff
                    jobs[j]['end_time'] = ending_time + diff
                Msg_counter += 1

    Makespan = max(jobs[j]['end_time'] for j in range(len(jobs)))

    return Makespan

# Generate application and platform model

# Draw a random acyclic Directed graph for Jobs
num_jobs = 10  # select the number of jobs 
G = nx.gnp_random_graph(num_jobs, 0.25, directed=True)
DAG = nx.DiGraph([(u, v) for (u, v) in G.edges() if u < v])

# Get Edge list from the graph
Edge_list = [e for e in DAG.edges]

# Create Job Profile

# Define max parameters
min_wcet = 1          # Minimum Worst Case execution time for jobs
max_wcet = 25         # Maximum Worst Case execution time for jobs
min_msg_sizes = 16    # Minimum Message Size
max_msg_sizes = 100   # Maximum Message Size

# Randomize Job attributes
wcets = [random.randint(min_wcet, max_wcet) for _ in range(num_jobs)]
msg_sizes = [random.randint(min_msg_sizes, max_msg_sizes) for _ in range(num_jobs)]

# Load SNAP graph precedence into variable
parents = [[] for _ in range(num_jobs)]
children = [[] for _ in range(num_jobs)]

for i in range(len(Edge_list)):
    parent = Edge_list[i][0]
    child = Edge_list[i][1]
    parents[child].append(parent)
    children[parent].append(child)

# Create a jobs dictionary with the jobs
jobs = {i: {"wcet": wcets[i],
            "message_size": msg_sizes[i],
            "parents": parents[i],
            "children": children[i],
            "start_time": 0,
            "end_time": 0,
            "priority": 0,
            "end_system": 0} for i in range(num_jobs)}

# Create a messages dictionary
messages = {i: {"parent": 0,
                "child": 0,
                "sender": 0,
                "receiver": 0,
                "route": [],
                "start_time": 0,
                "finish_time": 0} for i in range(len(Edge_list))}

# Create your Platform model

# Define parameters
num_of_processors = 4
num_of_routers = 2
Links = [(1, 5), (2, 5), (5, 6), (3, 6), (4, 6)]  # define your connection (manually)
end_systems = [i + 1 for i in range(num_of_processors)]
routers = [i + num_of_processors + 1 for i in range(num_of_routers)]

# Create the routes dictionary
routes = {}
for i in range(num_of_processors):
    for j in range(num_of_processors):
        if i != j:
            sender = end_systems[i]
            receiver = end_systems[j]
            route = find_path(Links, sender, receiver)
            routes[(sender, receiver)] = route

import itertools
import concurrent.futures
import threading

# Assuming we have num_jobs = 20 and end_systems = [1, 2, 3, 4]

# Generate all permutations of job priorities
priority_space = list(range(1, num_jobs+1))

# The function that will be distributed across the threads
def calculate_makespan(args):
    priority_assignment, processor_assignment, jobs = args
    for i in range(len(jobs)):
        jobs[i]['priority'] = priority_assignment[i]
        jobs[i]['end_system'] = processor_assignment[i]
    current_solution = jobs.copy()
    current_makespan = Schedule(jobs, routes, end_systems, messages, Links)
    with lock:
        if current_makespan < best_solution[0]:
            best_solution[0] = current_makespan
            best_solution[1] = current_solution

# The lock is needed to prevent multiple threads from updating the best solution simultaneously
lock = threading.Lock()

# The best solution found so far, stored in a list to allow in-place modification
best_solution = [99999, None]  # Initialize with a dummy solution with makespan +inf

# Define the number of threads to be used
num_threads = 1000  # Update this value according to your requirements

# Create a ThreadPoolExecutor
with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
    # Generate all combinations with repetition for end systems assignments
    processor_space = list(itertools.product(end_systems, repeat=num_jobs))

    for priority_assignment in itertools.permutations(priority_space):
        for processor_assignment in processor_space:
            # Each tuple of priority_assignment, processor_assignment, and jobs forms a single task
            executor.submit(calculate_makespan, (priority_assignment, processor_assignment, jobs))

print("Best makespan: ", best_solution[0])
print("Best solution: ", best_solution[1])
