# -*- coding: utf-8 -*-
"""Optimized_Scheduling_Brute_Force.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SQpUbRaoseI1KtAcuTH-41TF7pHSBcAH
"""

#Imports
import random
import networkx as nx
from networkx import Graph
from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
import copy as copy
import multiprocessing
import itertools
import itertools
import concurrent.futures
import threading

# Function Definitions

def comm_cost(route, message_size):
  hops = len(route)-1
  bandwidth = 32 #Insert the bandwidth of your links here
  m_size=int(message_size/bandwidth)
  cost = (hops * m_size)
  return cost,m_size

def Extract_Highest_Priority(jobs,Ready_Jobs):
  priorities = []
  for i in range(len(Ready_Jobs)):
    prior = jobs[Ready_Jobs[i]]['priority']
    priorities.append(prior)
  min_value = min(priorities)
  idx = priorities.index(min_value)
  
  return Ready_Jobs[idx]


def traffic_control_reserve(Injection, path, message_size,path_cost,overwrite):
  
  #print("parent finish time:", Injection)
  #print("Path:", path)
  #print("message_size:", message_size)
  Current_Router_start = Injection - message_size
  Current_Router_end  = Injection + path_cost

  for count in range(len(path)-1):
    Current_Router = [path[count],path[count+1]]
    Current_Router_start = Current_Router_start + message_size
    Current_Router_end = Current_Router_start + message_size
    Current_Router_start,Current_Router_end = check_collision(Current_Router,Current_Router_start,Current_Router_end,overwrite)
    
  #print("current end time:" , Current_Router_end)
  Delta_cost= Current_Router_end - (Injection + path_cost)
  #print("Delta cost: ", Delta_cost)
  #print("Router allocations: ", Routers_start_end)

  return Delta_cost

def check_collision(Current_Router, Current_Router_start, Current_Router_end,overwrite):
  list_name = str(np.min(Current_Router))+str(np.max(Current_Router))
  list_name = "cl_" + list_name
  
  current_list = globals()[list_name]
  #print(list_name, ":", current_list) #Debugging
  
  for search in range(len(current_list)):
    
    while(((Current_Router_start >= current_list[search][0]) and (Current_Router_start < current_list[search][1])) or ((Current_Router_end > current_list[search][0]) and (Current_Router_end <= current_list[search][1]))):
      #print("collision detected \n __________________________ \n ")
      Current_Router_start = Current_Router_start+1
      Current_Router_end = Current_Router_end +1
  
  if overwrite ==1:
    globals()[list_name].append([Current_Router_start,Current_Router_end])
  #print(list_name, " after modification :", current_list)

  return Current_Router_start,Current_Router_end

#The find path function is used to define the routes of the platform model using Breadth-First Search

def find_path(connections, start_node, end_node):
    # Create nodes
    nodes = set()
    for connection in connections:
        nodes.add(connection[0])
        nodes.add(connection[1])

    # Create adjacency list
    adjacency_list = {}
    for connection in connections:
        node1 = connection[0]
        node2 = connection[1]
        if node1 not in adjacency_list:
            adjacency_list[node1] = []
        if node2 not in adjacency_list:
            adjacency_list[node2] = []
        adjacency_list[node1].append(node2)
        adjacency_list[node2].append(node1)

    # Find path using BFS
    visited = set()
    queue = [[start_node]]
    while queue:
        path = queue.pop(0)
        node = path[-1]
        if node == end_node:
            return path
        elif node not in visited:
            for neighbor in adjacency_list.get(node, []):
                new_path = list(path)
                new_path.append(neighbor)
                queue.append(new_path)
            visited.add(node)
    return None

    #function to transform dicts into Pandas dataframe
def dict_to_dataframe(dictionary):
    # Create an empty DataFrame
    df = pd.DataFrame()

    # Iterate over the dictionary entries
    for key, attributes in dictionary.items():
        # Convert the attributes to a DataFrame
        attr_df = pd.DataFrame.from_dict(attributes, orient='index').transpose()
        
        
        # Concatenate the DataFrame to the main DataFrame
        df = pd.concat([df, attr_df], ignore_index=True)
    
    return df
  
def Schedule(jobs, routes, end_systems, messages, links):
    # Reconstructor
    Ready_Jobs = []
    Finished_jobs = []

    processor_endTime = [0 for j in range(len(end_systems))]

    # Prepare the Ready Jobs vector
    for i in range(len(jobs)):
        if jobs[i]['parents'] == []:
            Ready_Jobs.append(i)

    while Ready_Jobs != []:
        # Check for Job with highest priority
        Job = Extract_Highest_Priority(jobs,Ready_Jobs)

        # Extract end system
        End_system = jobs[Job]['end_system']

        # Extract execution time
        execution_time = jobs[Job]['wcet']
        
        #print("Ready Jobs : ", Ready_Jobs) #Debugging
        #print("Current Job : ", Job, "/Processor :", End_system, "/Wcet : ", execution_time)
        
        # Allocate Job to its End_system and fill out the dictionary with start/end time
        # Account for parents end time
        parents_job = jobs[Job]['parents']
        parents_end_times = [jobs[parent]['end_time'] for parent in parents_job]
        parents_end_times.append(processor_endTime[End_system - 1])
        maxi = max(parents_end_times)
        jobs[Job]["start_time"] = maxi
        processor_endTime[End_system - 1] = maxi + execution_time
        jobs[Job]["end_time"] = processor_endTime[End_system - 1]

        # Add Job to the finished job list and remove Job from the Job Ready list
        Finished_jobs.append(Job)
        Ready_Jobs.remove(Job)

        # Add free jobs after executing their parents
        children = jobs[Job]['children']

        for child in children:
            if set(jobs[child]['parents']).issubset(Finished_jobs):
                Ready_Jobs.append(child)
                Ready_Jobs = list(set(Ready_Jobs))

    for i in range(len(links)):
        name = "cl_" + str(links[i][0]) + str(links[i][1])
        globals()[name] = []

    Msg_counter = 0
    for i in Finished_jobs:
        processor_sender = jobs[i]['end_system']
        Msg_Size = jobs[i]['message_size']
        children = jobs[i]['children']
        Injection_time = jobs[i]['end_time']
        for j in children:
            processor_receiver = jobs[j]['end_system']
            if processor_sender == processor_receiver:
                Msg_Size = 0
                Route = []
                messages[Msg_counter]['route'] = []
                messages[Msg_counter]['parent'] = i
                messages[Msg_counter]['child'] = j
                messages[Msg_counter]['start_time'] = Injection_time
                messages[Msg_counter]['finish_time'] = Injection_time
                messages[Msg_counter]['sender'] = processor_sender
                messages[Msg_counter]['receiver'] = processor_receiver
                Msg_counter += 1
            else:
                Route = routes.get((processor_sender, processor_receiver))
                Cost, msize = comm_cost(Route, Msg_Size)
                col_costs = traffic_control_reserve(Injection_time, Route, msize, Cost, 1)
                comm_costs = Cost + col_costs
                messages[Msg_counter]['start_time'] = Injection_time
                messages[Msg_counter]['finish_time'] = Injection_time + comm_costs
                messages[Msg_counter]['parent'] = i
                messages[Msg_counter]['child'] = j
                messages[Msg_counter]['route'] = Route
                messages[Msg_counter]['sender'] = processor_sender
                messages[Msg_counter]['receiver'] = processor_receiver
                if jobs[j]['start_time'] < messages[Msg_counter]['finish_time']:
                    starting_time = jobs[j]['start_time']
                    ending_time = jobs[j]['end_time']
                    diff = messages[Msg_counter]['finish_time'] - starting_time
                    jobs[j]['start_time'] = starting_time + diff
                    jobs[j]['end_time'] = ending_time + diff
                Msg_counter += 1

    Makespan = max(jobs[j]['end_time'] for j in range(len(jobs)))

    # Return the makespan
    return Makespan

# Generate application and platform model

# Draw a random acyclic Directed graph for Jobs
num_jobs = 10  # select the number of jobs 
G = nx.gnp_random_graph(num_jobs, 0.25, directed=True)
DAG = nx.DiGraph([(u, v) for (u, v) in G.edges() if u < v])

# Get Edge list from the graph
Edge_list = [e for e in DAG.edges]

# Create Job Profile

# Define max parameters
min_wcet = 1          # Minimum Worst Case execution time for jobs
max_wcet = 25         # Maximum Worst Case execution time for jobs
min_msg_sizes = 16    # Minimum Message Size
max_msg_sizes = 100   # Maximum Message Size

# Randomize Job attributes
wcets = [random.randint(min_wcet, max_wcet) for _ in range(num_jobs)]
msg_sizes = [random.randint(min_msg_sizes, max_msg_sizes) for _ in range(num_jobs)]

# Load SNAP graph precedence into variable
parents = [[] for _ in range(num_jobs)]
children = [[] for _ in range(num_jobs)]

for i in range(len(Edge_list)):
    parent = Edge_list[i][0]
    child = Edge_list[i][1]
    parents[child].append(parent)
    children[parent].append(child)

# Create a jobs dictionary with the jobs
jobs = {i: {"wcet": wcets[i],
            "message_size": msg_sizes[i],
            "parents": parents[i],
            "children": children[i],
            "start_time": 0,
            "end_time": 0,
            "priority": 0,
            "end_system": 0} for i in range(num_jobs)}

# Create a messages dictionary
messages = {i: {"parent": 0,
                "child": 0,
                "sender": 0,
                "receiver": 0,
                "route": [],
                "start_time": 0,
                "finish_time": 0} for i in range(len(Edge_list))}

# Create your Platform model

# Define parameters
num_of_processors = 4
num_of_routers = 2
Links = [(1, 5), (2, 5), (5, 6), (3, 6), (4, 6)]  # define your connection (manually)
end_systems = [i + 1 for i in range(num_of_processors)]
routers = [i + num_of_processors + 1 for i in range(num_of_routers)]

# Create the routes dictionary
routes = {}
for i in range(num_of_processors):
    for j in range(num_of_processors):
        if i != j:
            sender = end_systems[i]
            receiver = end_systems[j]
            route = find_path(Links, sender, receiver)
            routes[(sender, receiver)] = route


# Assuming we have num_jobs = 20 and end_systems = [1, 2, 3, 4]

# Generate all permutations of job priorities
priority_space = list(range(1, num_jobs+1))

# The function that will be distributed across the threads
def calculate_makespan(args):
    priority_assignment, processor_assignment, jobs = args
    for i in range(len(jobs)):
        jobs[i]['priority'] = priority_assignment[i]
        jobs[i]['end_system'] = processor_assignment[i]
    current_solution = jobs.copy()  # You may need to deep copy if the jobs list contains mutable objects
    current_makespan = Schedule(jobs, routes, end_systems, messages, Links)
    with lock:
        if current_makespan < best_solution[0]:
            best_solution[0] = current_makespan
            best_solution[1] = current_solution

# The lock is needed to prevent multiple threads from updating the best solution simultaneously
lock = threading.Lock()

# The best solution found so far, stored in a list to allow in-place modification
best_solution = [99999, None]  # Initialize with a dummy solution with makespan +inf

# Define the number of threads to be used
num_threads = 1000  # Update this value according to your requirements

# Create a ThreadPoolExecutor
with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
    # Generate all combinations with repetition for end systems assignments
    processor_space = list(itertools.product(end_systems, repeat=num_jobs))

    for priority_assignment in itertools.permutations(priority_space):
        for processor_assignment in processor_space:
            # Each tuple of priority_assignment, processor_assignment, and jobs forms a single task
            executor.submit(calculate_makespan, (priority_assignment, processor_assignment, jobs))

print("Best makespan: ", best_solution[0])
print("Best solution: ", best_solution[1])

print("Best makespan: ", best_solution[0])
print("Best solution: ", best_solution[1])
