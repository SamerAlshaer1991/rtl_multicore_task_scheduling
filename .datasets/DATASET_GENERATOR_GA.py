# -*- coding: utf-8 -*-
"""Dataset_generator_v4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v6HLLPbwp1nwPFb9gfImgeWMcrhk2mF7
"""

# Imports
import random
import networkx as nx
from networkx import Graph
from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
import copy as copy
import multiprocessing
import concurrent.futures
import pickle

# Function Definitions

def comm_cost(route, message_size):
    """Calculates the communication cost based on the route and message size.

    Args:
        route (list): List of nodes representing the route.
        message_size (int): Size of the message.

    Returns:
        tuple: Communication cost and modified message size.
    """
    hops = len(route) - 1
    bandwidth = 32  # Insert the bandwidth of your links here
    m_size = int(message_size / bandwidth)
    cost = hops * m_size
    return cost, m_size


def Extract_Highest_Priority(jobs, Ready_Jobs):
    """Extracts the job with the highest priority from the ready jobs list.

    Args:
        jobs (dict): Dictionary containing job information.
        Ready_Jobs (list): List of job indices representing the ready jobs.

    Returns:
        int: Index of the job with the highest priority.
    """
    priorities = []
    for i in range(len(Ready_Jobs)):
        prior = jobs[Ready_Jobs[i]]['priority']
        priorities.append(prior)
    min_value = min(priorities)
    idx = priorities.index(min_value)
    return Ready_Jobs[idx]


def traffic_control_reserve(Injection, path, message_size, path_cost, overwrite):
    """Performs traffic control and reserves bandwidth for a message along a path.

    Args:
        Injection (int): Injection time of the message.
        path (list): List of nodes representing the path.
        message_size (int): Size of the message.
        path_cost (int): Cost associated with the path.
        overwrite (int): Flag indicating whether to update the router allocations.

    Returns:
        int: Delta cost representing the difference between the expected and actual end time.
    """
    Current_Router_start = Injection - message_size
    Current_Router_end = Injection + path_cost

    for count in range(len(path) - 1):
        Current_Router = [path[count], path[count + 1]]
        Current_Router_start = Current_Router_start + message_size
        Current_Router_end = Current_Router_start + message_size
        Current_Router_start, Current_Router_end = check_collision(Current_Router, Current_Router_start,
                                                                  Current_Router_end, overwrite)

    Delta_cost = Current_Router_end - (Injection + path_cost)
    return Delta_cost


def check_collision(Current_Router, Current_Router_start, Current_Router_end, overwrite):
    """Checks for collisions in router allocations and updates them accordingly.

    Args:
        Current_Router (list): List of nodes representing the current router.
        Current_Router_start (int): Start time of the current router.
        Current_Router_end (int): End time of the current router.
        overwrite (int): Flag indicating whether to update the router allocations.

    Returns:
        tuple: Updated start and end time of the current router.
    """
    list_name = "cl_" + str(np.min(Current_Router)) + str(np.max(Current_Router))
    list_name = "cl_" + list_name

    current_list = globals()[list_name]

    for search in range(len(current_list)):
        while ((Current_Router_start >= current_list[search][0] and Current_Router_start < current_list[search][1]) or
               (Current_Router_end > current_list[search][0] and Current_Router_end <= current_list[search][1])):
            Current_Router_start = Current_Router_start + 1
            Current_Router_end = Current_Router_end + 1

    if overwrite == 1:
        globals()[list_name].append([Current_Router_start, Current_Router_end])

    return Current_Router_start, Current_Router_end


def find_path(connections, start_node, end_node):
    """Finds the path between two nodes using Breadth-First Search.

    Args:
        connections (list): List of connections between nodes.
        start_node (int): Starting node.
        end_node (int): Ending node.

    Returns:
        list: List of nodes representing the path.
    """
    # Create nodes
    nodes = set()
    for connection in connections:
        nodes.add(connection[0])
        nodes.add(connection[1])

    # Create adjacency list
    adjacency_list = {}
    for connection in connections:
        node1 = connection[0]
        node2 = connection[1]
        if node1 not in adjacency_list:
            adjacency_list[node1] = []
        if node2 not in adjacency_list:
            adjacency_list[node2] = []
        adjacency_list[node1].append(node2)
        adjacency_list[node2].append(node1)

    # Find path using BFS
    visited = set()
    queue = [[start_node]]
    while queue:
        path = queue.pop(0)
        node = path[-1]
        if node == end_node:
            return path
        elif node not in visited:
            for neighbor in adjacency_list.get(node, []):
                new_path = list(path)
                new_path.append(neighbor)
                queue.append(new_path)
            visited.add(node)
    return None


def generate_chromosome(jobs, end_systems):
    """Generates a random chromosome.

    Args:
        jobs (dict): Dictionary containing job information.
        end_systems (list): List of end systems (processors).

    Returns:
        dict: Generated chromosome (job assignment).
    """
    # Get the list of all possible priority numbers
    priorities = list(range(1, len(jobs) + 1))
    random.shuffle(priorities)

    # Assign priorities to the tasks
    for i in range(len(jobs)):
        jobs[i]['priority'] = priorities[i]

    # Assign random processors to the tasks
    processors = random.choices(end_systems, k=len(jobs))
    for i in range(len(jobs)):
        jobs[i]['end_system'] = processors[i]

    chromo = jobs
    return chromo


def fitness_function(chromo):
    """Evaluates the fitness of a chromosome.

    Args:
        chromo (dict): Chromosome (job assignment).

    Returns:
        float: Fitness value.
    """
    # Use the Reconstruction model to generate a schedule and compute its makespan
    Makespan = Schedule(chromo, routes, end_systems, messages, Links)

    # Return the inverse of the makespan as the fitness value
    return 1.0 / Makespan


def generate_population(POPULATION_SIZE):
    """Generates an initial population of chromosomes.

    Args:
        POPULATION_SIZE (int): Size of the population.

    Returns:
        list: Initial population of chromosomes.
    """
    population = []
    for i in range(POPULATION_SIZE):
        chromosome = generate_chromosome(jobs, end_systems)
        population.append(chromosome)
    return population


def selection(fitness_values, population):
    """Performs selection of individuals based on their fitness values.

    Args:
        fitness_values (list): List of fitness values for the population.
        population (list): List of chromosomes (population).

    Returns:
        tuple: Selected fitness values and corresponding population.
    """
    selection_size = 10

    # Select half the solutions at random
    random_indices = np.random.choice(len(population), size=selection_size // 2, replace=False)
    selected_population = [population[i] for i in random_indices]
    selected_fitness = [fitness_values[i] for i in random_indices]

    # Compare the fitness of the other half and select the best ones
    remaining_indices = [i for i in range(len(population)) if i not in random_indices]
    remaining_fitness = [fitness_values[i] for i in remaining_indices]
    remaining_population = [population[i] for i in remaining_indices]
    sorted_indices = np.argsort(remaining_fitness)[-selection_size // 2:]
    sorted_population = [remaining_population[i] for i in sorted_indices]
    sorted_fitness = [remaining_fitness[i] for i in sorted_indices]

    # Combine the randomly selected and best solutions
    selected_population.extend(sorted_population)
    selected_fitness.extend(sorted_fitness)

    return selected_fitness, selected_population


def mutation(chromosome, mutation_rate):
    """Performs mutation on a chromosome.

    Args:
        chromosome (dict): Chromosome (job assignment).
        mutation_rate (float): Probability of mutation.

    Returns:
        dict: Mutated chromosome.
    """
    maximum = max(entry['end_system'] for entry in chromosome.values())

    # Iterate through the jobs in the chromosome
    for i in range(len(chromosome)):
        # With a certain probability, mutate the processor of the job
        if random.random() < mutation_rate:
            chromosome[i]['end_system'] = random.randint(1, maximum)
        # With another probability, swap the priority of this job with another job
        if random.random() < mutation_rate:
            # Choose a random job to swap priorities with
            j = random.randint(0, len(chromosome) - 1)
            # Swap the priorities of the two jobs
            temp_priority = chromosome[i]['priority']
            chromosome[i]['priority'] = chromosome[j]['priority']
            chromosome[j]['priority'] = temp_priority

    return chromosome


def dict_to_dataframe(dictionary):
    """Converts a dictionary to a pandas DataFrame.

    Args:
        dictionary (dict): Dictionary to be converted.

    Returns:
        pandas.DataFrame: Converted DataFrame.
    """
    df = pd.DataFrame()

    for key, attributes in dictionary.items():
        attr_df = pd.DataFrame.from_dict(attributes, orient='index').transpose()
        df = pd.concat([df, attr_df], ignore_index=True)

    return df


def Schedule(jobs, routes, end_systems, messages, links):
    """Generates a schedule for the jobs based on the application and platform model.

    Args:
        jobs (dict): Dictionary containing job information.
        routes (dict): Dictionary of routes between processors.
        end_systems (list): List of end systems (processors).
        messages (dict): Dictionary containing message information.
        links (list): List of connections between routers.

    Returns:
        int: Makespan of the schedule.
    """
    Ready_Jobs = []
    Finished_jobs = []
    processor_endTime = [0 for j in range(len(end_systems))]

    # Prepare the Ready Jobs vector
    for i in range(len(jobs)):
        if jobs[i]['parents'] == []:
            Ready_Jobs.append(i)

    while Ready_Jobs != []:
        # Check for Job with highest priority
        Job = Extract_Highest_Priority(jobs, Ready_Jobs)

        # Extract end system
        End_system = jobs[Job]['end_system']

        # Extract execution time
        execution_time = jobs[Job]['wcet']

        # Allocate Job to its End_system and fill out the dictionary with start/end time
        parents_job = jobs[Job]['parents']
        parents_end_times = [jobs[parent]['end_time'] for parent in parents_job]
        parents_end_times.append(processor_endTime[End_system - 1])
        maxi = max(parents_end_times)
        jobs[Job]["start_time"] = maxi
        processor_endTime[End_system - 1] = maxi + execution_time
        jobs[Job]["end_time"] = processor_endTime[End_system - 1]

        # Add Job to the finished job list and remove Job from the Job Ready list
        Finished_jobs.append(Job)
        Ready_Jobs.remove(Job)

        # Add free jobs after executing their parents
        children = jobs[Job]['children']

        for child in children:
            if set(jobs[child]['parents']).issubset(Finished_jobs):
                Ready_Jobs.append(child)
                Ready_Jobs = list(set(Ready_Jobs))

    for i in range(len(links)):
        name = "cl_" + str(links[i][0]) + str(links[i][1])
        globals()[name] = []

    Msg_counter = 0
    for i in Finished_jobs:
        processor_sender = jobs[i]['end_system']
        Msg_Size = jobs[i]['message_size']
        children = jobs[i]['children']
        Injection_time = jobs[i]['end_time']
        for j in children:
            processor_receiver = jobs[j]['end_system']
            if processor_sender == processor_receiver:
                Msg_Size = 0
                Route = []
                messages[Msg_counter]['route'] = []
                messages[Msg_counter]['parent'] = i
                messages[Msg_counter]['child'] = j
                messages[Msg_counter]['start_time'] = Injection_time
                messages[Msg_counter]['finish_time'] = Injection_time
                messages[Msg_counter]['sender'] = processor_sender
                messages[Msg_counter]['receiver'] = processor_receiver
                Msg_counter += 1
            else:
                Route = routes.get((processor_sender, processor_receiver))
                Cost, msize = comm_cost(Route, Msg_Size)
                col_costs = traffic_control_reserve(Injection_time, Route, msize, Cost, 1)
                comm_costs = Cost + col_costs
                messages[Msg_counter]['start_time'] = Injection_time
                messages[Msg_counter]['finish_time'] = Injection_time + comm_costs
                messages[Msg_counter]['parent'] = i
                messages[Msg_counter]['child'] = j
                messages[Msg_counter]['route'] = Route
                messages[Msg_counter]['sender'] = processor_sender
                messages[Msg_counter]['receiver'] = processor_receiver
                if jobs[j]['start_time'] < messages[Msg_counter]['finish_time']:
                    starting_time = jobs[j]['start_time']
                    ending_time = jobs[j]['end_time']
                    diff = messages[Msg_counter]['finish_time'] - starting_time
                    jobs[j]['start_time'] = starting_time + diff
                    jobs[j]['end_time'] = ending_time + diff
                Msg_counter += 1

    Makespan = max(jobs[j]['end_time'] for j in range(len(jobs)))
    return Makespan


def crossover(parent1, parent2):
    """Performs crossover between two parents to create two children.

    Args:
        parent1 (dict): First parent chromosome.
        parent2 (dict): Second parent chromosome.

    Returns:
        tuple: Two children chromosomes.
    """
    size = len(parent1)

    # Generate a random index
    idx = random.randint(1, size - 1)

    # Create children as copies of parents
    child1, child2 = copy.deepcopy(parent1), copy.deepcopy(parent2)

    # Swap priorities and end_system for the jobs from idx to end between child1 and child2
    for i in range(idx, size):
        child1[i]['priority'], child2[i]['priority'] = child2[i]['priority'], child1[i]['priority']
        child1[i]['end_system'], child2[i]['end_system'] = child2[i]['end_system'], child1[i]['end_system']

    return child1, child2


def genetic_algorithm(population, fitness_func, mutation_rate, num_generations):
    """Performs a genetic algorithm to optimize the population of chromosomes.

    Args:
        population (list): Initial population of chromosomes.
        fitness_func (function): Fitness function to evaluate the chromosomes.
        mutation_rate (float): Probability of mutation.
        num_generations (int): Number of generations to evolve.

    Returns:
        list: Final population of chromosomes.
    """
    for generation in range(num_generations):
        # Evaluate fitness of the population
        fitness_scores = [fitness_func(individual) for individual in population]

        # Selection
        selected_fitness, selected_population = selection(fitness_scores, population)

        # Crossover
        children = []
        for i in range(0, len(selected_population), 2):
            child1, child2 = crossover(selected_population[i], selected_population[i + 1])
            children.append(child1)
            children.append(child2)

        # Mutation
        for i in range(len(children)):
            children[i] = mutation(children[i], mutation_rate)

        # Update population
        population = children
    return population


# Generate application and platform model

number_of_sample = 1000
sample_no = 0

# Create your Platform model

# Define parameters
num_of_processors = 4
num_of_routers = 2
Links = [(1, 5), (2, 5), (5, 6), (3, 6), (4, 6)]  # define your connection (manually)
end_systems = [i + 1 for i in range(num_of_processors)]
routers = [i + num_of_processors + 1 for i in range(num_of_routers)]

# Create the routes dictionary
routes = {}
for i in range(num_of_processors):
    for j in range(num_of_processors):
        if i != j:
            sender = end_systems[i]
            receiver = end_systems[j]
            route = find_path(Links, sender, receiver)
            routes[(sender, receiver)] = route


# Draw a random acyclic Directed graph for Jobs

num_jobs = 10  # select the number of jobs

while sample_no != number_of_sample:
    G = nx.gnp_random_graph(num_jobs, 0.25, directed=True)
    DAG = nx.DiGraph([(u, v) for (u, v) in G.edges() if u < v])

    # Get Edge list from the graph
    Edge_list = [e for e in DAG.edges]

    # Create Job Profile

    # Define max parameters
    min_wcet = 1  # Minimum Worst Case execution time for jobs
    max_wcet = 25  # Maximum Worst Case execution time for jobs
    min_msg_sizes = 16  # Minimum Message Size
    max_msg_sizes = 100  # Maximum Message Size

    # Randomize Job attributes
    wcets = [random.randint(min_wcet, max_wcet) for _ in range(num_jobs)]
    msg_sizes = [random.randint(min_msg_sizes, max_msg_sizes) for _ in range(num_jobs)]

    # Load graph precedence into variable
    parents = [[] for _ in range(num_jobs)]
    children = [[] for _ in range(num_jobs)]

    for i in range(len(Edge_list)):
        parent = Edge_list[i][0]
        child = Edge_list[i][1]
        parents[child].append(parent)
        children[parent].append(child)

    # Create a jobs dictionary with the jobs
    jobs = {
        i: {
            "wcet": wcets[i],
            "message_size": msg_sizes[i],
            "parents": parents[i],
            "children": children[i],
            "start_time": 0,
            "end_time": 0,
            "priority": 0,
            "end_system": 0
        } for i in range(num_jobs)
    }

    # Create a messages dictionary
    messages = {
        i: {
            "parent": 0,
            "child": 0,
            "sender": 0,
            "receiver": 0,
            "route": [],
            "start_time": 0,
            "finish_time": 0
        } for i in range(len(Edge_list))
    }

    # Parameters for the GA scheduler
    POPULATION_SIZE = 1000
    ELITE_SIZE = 5
    mutation_rate = 0.5
    MAX_GENERATIONS = 1000
    NUM_THREADS = 30  # You can adjust this value as per your system's capacity

    maximum_val = 0

    # Implementing a break counter to speed up the operation
    break_count = 0

    # Generate an initial population
    population = generate_population(POPULATION_SIZE)

    # Initialize the executor with NUM_THREADS
    executor = concurrent.futures.ProcessPoolExecutor(max_workers=NUM_THREADS)

    # Run the GA scheduler for a fixed number of generations
    for generation in range(MAX_GENERATIONS):

        # Evaluate the fitness of each chromosome in the population
        fitness_values = list(executor.map(fitness_function, population))  # Use map function of executor

        # store the strongest gene
        max_value = max(fitness_values)
        if max_value > maximum_val:
            max_index = fitness_values.index(max_value)
            best_gene = copy.deepcopy(population[max_index])
            maximum_val = max_value
            break_count = 0

        # Select a portion of the population to produce offspring
        selected_fitness, selected_population = selection(fitness_values, population)

        # Create offspring by applying mutation to the selected individuals
        offspring = []
        for i in range(len(selected_population)):
            chromosome = selected_population[i]
            mutated_chromosome = mutation(chromosome, mutation_rate)
            offspring.append(mutated_chromosome)

        # Add the elite individuals (i.e. the top performers from the previous generation) to the new population
        elite_indices = np.argsort(selected_fitness)[-ELITE_SIZE:]
        elite_population = [selected_population[i] for i in elite_indices]
        new_population = elite_population + offspring

        # Update the population for the next generation
        population = new_population

        best_fitness = max(selected_fitness)
        break_count += 1
        if break_count == 300:
            break

    name = "/content/drive/MyDrive/Datasets/10_jobs_GA/"
    name = name + "sample_" + str(sample_no) + ".p"
    sample_no += 1
    pickle.dump(best_gene, open(name, "wb"))
    # print("Best Gene" ,best_gene)
    # print("Best Fitness:", maximum_val)
